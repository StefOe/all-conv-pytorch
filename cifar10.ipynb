{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/StefOe/all-conv-pytorch/blob/master/cifar10.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "NjsA9TTlvXU7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cuda = True\n",
        "train_batch_size = 32\n",
        "test_batch_size = 124\n",
        "best_loss = float(\"inf\")\n",
        "best_epoch = -1\n",
        "dataset_path = './cifar10'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0LLDiZnvXU-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    from os import path\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "    accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.1-{platform}-linux_x86_64.whl\n",
        "    import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_41e1ZYvXVB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torchvision\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -q torchvision\n",
        "\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lam-625bvXVE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from allconv import AllConvNet\n",
        "except ModuleNotFoundError: \n",
        "    !wget https://github.com/StefOe/all-conv-pytorch/raw/HEAD/allconv.py\n",
        "    from allconv import AllConvNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZu8tSSYvXVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6c644d18-7c6e-4265-9820-ecad3b362f91"
      },
      "cell_type": "code",
      "source": [
        "cuda = cuda and torch.cuda.is_available()\n",
        "trainset = datasets.CIFAR10(root=dataset_path, train=True, download=True)\n",
        "train_mean = trainset.train_data.mean(axis=(0,1,2))/255  # [0.49139968  0.48215841  0.44653091]\n",
        "train_std = trainset.train_data.std(axis=(0,1,2))/255  # [0.24703223  0.24348513  0.26158784]\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std),\n",
        "])\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(datasets.CIFAR10(\n",
        "    root=dataset_path, train=True, download=True,\n",
        "    transform=transform_train),\n",
        "    batch_size=train_batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(root=dataset_path, train=False, download=True,\n",
        "    transform=transform_test),\n",
        "    batch_size=test_batch_size, shuffle=False, **kwargs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3WISJzjRvXVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = AllConvNet(3)\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "    optimizer, milestones=[200, 250, 300], gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5shX88fvvXVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
        "            \n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += criterion(output, target).data[0]\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(\n",
        "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), 100. * correct /\n",
        "            len(test_loader.dataset)))\n",
        "    \n",
        "    if loss.data[0] < best_loss:\n",
        "        best_epoch = epoch\n",
        "        best_loss = test_loss\n",
        "        model.save(\"best.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q_YHklUQvXVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2584
        },
        "outputId": "cfcd0c59-f322-4281-f8a1-5c3d3a3e9a43"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(350):\n",
        "    scheduler.step()\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.318764\n",
            "Train Epoch: 0 [320/50000 (1%)]\tLoss: 2.284923\n",
            "Train Epoch: 0 [640/50000 (1%)]\tLoss: 2.292436\n",
            "Train Epoch: 0 [960/50000 (2%)]\tLoss: 2.311650\n",
            "Train Epoch: 0 [1280/50000 (3%)]\tLoss: 2.293617\n",
            "Train Epoch: 0 [1600/50000 (3%)]\tLoss: 2.312588\n",
            "Train Epoch: 0 [1920/50000 (4%)]\tLoss: 2.293349\n",
            "Train Epoch: 0 [2240/50000 (4%)]\tLoss: 2.305540\n",
            "Train Epoch: 0 [2560/50000 (5%)]\tLoss: 2.298046\n",
            "Train Epoch: 0 [2880/50000 (6%)]\tLoss: 2.296811\n",
            "Train Epoch: 0 [3200/50000 (6%)]\tLoss: 2.313303\n",
            "Train Epoch: 0 [3520/50000 (7%)]\tLoss: 2.293413\n",
            "Train Epoch: 0 [3840/50000 (8%)]\tLoss: 2.283757\n",
            "Train Epoch: 0 [4160/50000 (8%)]\tLoss: 2.292461\n",
            "Train Epoch: 0 [4480/50000 (9%)]\tLoss: 2.316245\n",
            "Train Epoch: 0 [4800/50000 (10%)]\tLoss: 2.299819\n",
            "Train Epoch: 0 [5120/50000 (10%)]\tLoss: 2.299110\n",
            "Train Epoch: 0 [5440/50000 (11%)]\tLoss: 2.296137\n",
            "Train Epoch: 0 [5760/50000 (12%)]\tLoss: 2.322785\n",
            "Train Epoch: 0 [6080/50000 (12%)]\tLoss: 2.320367\n",
            "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 2.312265\n",
            "Train Epoch: 0 [6720/50000 (13%)]\tLoss: 2.299570\n",
            "Train Epoch: 0 [7040/50000 (14%)]\tLoss: 2.302444\n",
            "Train Epoch: 0 [7360/50000 (15%)]\tLoss: 2.299488\n",
            "Train Epoch: 0 [7680/50000 (15%)]\tLoss: 2.313710\n",
            "Train Epoch: 0 [8000/50000 (16%)]\tLoss: 2.296592\n",
            "Train Epoch: 0 [8320/50000 (17%)]\tLoss: 2.301164\n",
            "Train Epoch: 0 [8640/50000 (17%)]\tLoss: 2.324100\n",
            "Train Epoch: 0 [8960/50000 (18%)]\tLoss: 2.305176\n",
            "Train Epoch: 0 [9280/50000 (19%)]\tLoss: 2.305476\n",
            "Train Epoch: 0 [9600/50000 (19%)]\tLoss: 2.312772\n",
            "Train Epoch: 0 [9920/50000 (20%)]\tLoss: 2.306041\n",
            "Train Epoch: 0 [10240/50000 (20%)]\tLoss: 2.296396\n",
            "Train Epoch: 0 [10560/50000 (21%)]\tLoss: 2.300006\n",
            "Train Epoch: 0 [10880/50000 (22%)]\tLoss: 2.309260\n",
            "Train Epoch: 0 [11200/50000 (22%)]\tLoss: 2.300901\n",
            "Train Epoch: 0 [11520/50000 (23%)]\tLoss: 2.297949\n",
            "Train Epoch: 0 [11840/50000 (24%)]\tLoss: 2.303764\n",
            "Train Epoch: 0 [12160/50000 (24%)]\tLoss: 2.292515\n",
            "Train Epoch: 0 [12480/50000 (25%)]\tLoss: 2.307649\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 2.293421\n",
            "Train Epoch: 0 [13120/50000 (26%)]\tLoss: 2.305382\n",
            "Train Epoch: 0 [13440/50000 (27%)]\tLoss: 2.310208\n",
            "Train Epoch: 0 [13760/50000 (28%)]\tLoss: 2.300422\n",
            "Train Epoch: 0 [14080/50000 (28%)]\tLoss: 2.301601\n",
            "Train Epoch: 0 [14400/50000 (29%)]\tLoss: 2.289558\n",
            "Train Epoch: 0 [14720/50000 (29%)]\tLoss: 2.304086\n",
            "Train Epoch: 0 [15040/50000 (30%)]\tLoss: 2.306368\n",
            "Train Epoch: 0 [15360/50000 (31%)]\tLoss: 2.315406\n",
            "Train Epoch: 0 [15680/50000 (31%)]\tLoss: 2.305428\n",
            "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 2.309318\n",
            "Train Epoch: 0 [16320/50000 (33%)]\tLoss: 2.304356\n",
            "Train Epoch: 0 [16640/50000 (33%)]\tLoss: 2.305489\n",
            "Train Epoch: 0 [16960/50000 (34%)]\tLoss: 2.304996\n",
            "Train Epoch: 0 [17280/50000 (35%)]\tLoss: 2.296670\n",
            "Train Epoch: 0 [17600/50000 (35%)]\tLoss: 2.303545\n",
            "Train Epoch: 0 [17920/50000 (36%)]\tLoss: 2.305245\n",
            "Train Epoch: 0 [18240/50000 (36%)]\tLoss: 2.299135\n",
            "Train Epoch: 0 [18560/50000 (37%)]\tLoss: 2.304215\n",
            "Train Epoch: 0 [18880/50000 (38%)]\tLoss: 2.300796\n",
            "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 2.302184\n",
            "Train Epoch: 0 [19520/50000 (39%)]\tLoss: 2.307255\n",
            "Train Epoch: 0 [19840/50000 (40%)]\tLoss: 2.307089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [20160/50000 (40%)]\tLoss: 2.303979\n",
            "Train Epoch: 0 [20480/50000 (41%)]\tLoss: 2.300681\n",
            "Train Epoch: 0 [20800/50000 (42%)]\tLoss: 2.297668\n",
            "Train Epoch: 0 [21120/50000 (42%)]\tLoss: 2.301889\n",
            "Train Epoch: 0 [21440/50000 (43%)]\tLoss: 2.308232\n",
            "Train Epoch: 0 [21760/50000 (44%)]\tLoss: 2.291711\n",
            "Train Epoch: 0 [22080/50000 (44%)]\tLoss: 2.308837\n",
            "Train Epoch: 0 [22400/50000 (45%)]\tLoss: 2.309948\n",
            "Train Epoch: 0 [22720/50000 (45%)]\tLoss: 2.311386\n",
            "Train Epoch: 0 [23040/50000 (46%)]\tLoss: 2.307814\n",
            "Train Epoch: 0 [23360/50000 (47%)]\tLoss: 2.301917\n",
            "Train Epoch: 0 [23680/50000 (47%)]\tLoss: 2.297677\n",
            "Train Epoch: 0 [24000/50000 (48%)]\tLoss: 2.306062\n",
            "Train Epoch: 0 [24320/50000 (49%)]\tLoss: 2.302821\n",
            "Train Epoch: 0 [24640/50000 (49%)]\tLoss: 2.301436\n",
            "Train Epoch: 0 [24960/50000 (50%)]\tLoss: 2.305444\n",
            "Train Epoch: 0 [25280/50000 (51%)]\tLoss: 2.305934\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 2.298136\n",
            "Train Epoch: 0 [25920/50000 (52%)]\tLoss: 2.303322\n",
            "Train Epoch: 0 [26240/50000 (52%)]\tLoss: 2.304988\n",
            "Train Epoch: 0 [26560/50000 (53%)]\tLoss: 2.299243\n",
            "Train Epoch: 0 [26880/50000 (54%)]\tLoss: 2.300855\n",
            "Train Epoch: 0 [27200/50000 (54%)]\tLoss: 2.303395\n",
            "Train Epoch: 0 [27520/50000 (55%)]\tLoss: 2.295722\n",
            "Train Epoch: 0 [27840/50000 (56%)]\tLoss: 2.296248\n",
            "Train Epoch: 0 [28160/50000 (56%)]\tLoss: 2.300224\n",
            "Train Epoch: 0 [28480/50000 (57%)]\tLoss: 2.304283\n",
            "Train Epoch: 0 [28800/50000 (58%)]\tLoss: 2.301517\n",
            "Train Epoch: 0 [29120/50000 (58%)]\tLoss: 2.304567\n",
            "Train Epoch: 0 [29440/50000 (59%)]\tLoss: 2.303309\n",
            "Train Epoch: 0 [29760/50000 (60%)]\tLoss: 2.296966\n",
            "Train Epoch: 0 [30080/50000 (60%)]\tLoss: 2.302024\n",
            "Train Epoch: 0 [30400/50000 (61%)]\tLoss: 2.298754\n",
            "Train Epoch: 0 [30720/50000 (61%)]\tLoss: 2.304980\n",
            "Train Epoch: 0 [31040/50000 (62%)]\tLoss: 2.300902\n",
            "Train Epoch: 0 [31360/50000 (63%)]\tLoss: 2.301985\n",
            "Train Epoch: 0 [31680/50000 (63%)]\tLoss: 2.307223\n",
            "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 2.301080\n",
            "Train Epoch: 0 [32320/50000 (65%)]\tLoss: 2.303803\n",
            "Train Epoch: 0 [32640/50000 (65%)]\tLoss: 2.299667\n",
            "Train Epoch: 0 [32960/50000 (66%)]\tLoss: 2.304478\n",
            "Train Epoch: 0 [33280/50000 (67%)]\tLoss: 2.301566\n",
            "Train Epoch: 0 [33600/50000 (67%)]\tLoss: 2.303467\n",
            "Train Epoch: 0 [33920/50000 (68%)]\tLoss: 2.304851\n",
            "Train Epoch: 0 [34240/50000 (68%)]\tLoss: 2.302835\n",
            "Train Epoch: 0 [34560/50000 (69%)]\tLoss: 2.300933\n",
            "Train Epoch: 0 [34880/50000 (70%)]\tLoss: 2.301857\n",
            "Train Epoch: 0 [35200/50000 (70%)]\tLoss: 2.302307\n",
            "Train Epoch: 0 [35520/50000 (71%)]\tLoss: 2.297467\n",
            "Train Epoch: 0 [35840/50000 (72%)]\tLoss: 2.302997\n",
            "Train Epoch: 0 [36160/50000 (72%)]\tLoss: 2.300230\n",
            "Train Epoch: 0 [36480/50000 (73%)]\tLoss: 2.302333\n",
            "Train Epoch: 0 [36800/50000 (74%)]\tLoss: 2.302072\n",
            "Train Epoch: 0 [37120/50000 (74%)]\tLoss: 2.302149\n",
            "Train Epoch: 0 [37440/50000 (75%)]\tLoss: 2.304179\n",
            "Train Epoch: 0 [37760/50000 (75%)]\tLoss: 2.304863\n",
            "Train Epoch: 0 [38080/50000 (76%)]\tLoss: 2.303800\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 2.304170\n",
            "Train Epoch: 0 [38720/50000 (77%)]\tLoss: 2.301377\n",
            "Train Epoch: 0 [39040/50000 (78%)]\tLoss: 2.303294\n",
            "Train Epoch: 0 [39360/50000 (79%)]\tLoss: 2.301457\n",
            "Train Epoch: 0 [39680/50000 (79%)]\tLoss: 2.301634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [40000/50000 (80%)]\tLoss: 2.307673\n",
            "Train Epoch: 0 [40320/50000 (81%)]\tLoss: 2.299012\n",
            "Train Epoch: 0 [40640/50000 (81%)]\tLoss: 2.306967\n",
            "Train Epoch: 0 [40960/50000 (82%)]\tLoss: 2.301695\n",
            "Train Epoch: 0 [41280/50000 (83%)]\tLoss: 2.303169\n",
            "Train Epoch: 0 [41600/50000 (83%)]\tLoss: 2.301627\n",
            "Train Epoch: 0 [41920/50000 (84%)]\tLoss: 2.302511\n",
            "Train Epoch: 0 [42240/50000 (84%)]\tLoss: 2.301566\n",
            "Train Epoch: 0 [42560/50000 (85%)]\tLoss: 2.302002\n",
            "Train Epoch: 0 [42880/50000 (86%)]\tLoss: 2.303195\n",
            "Train Epoch: 0 [43200/50000 (86%)]\tLoss: 2.299551\n",
            "Train Epoch: 0 [43520/50000 (87%)]\tLoss: 2.302970\n",
            "Train Epoch: 0 [43840/50000 (88%)]\tLoss: 2.302221\n",
            "Train Epoch: 0 [44160/50000 (88%)]\tLoss: 2.301253\n",
            "Train Epoch: 0 [44480/50000 (89%)]\tLoss: 2.299019\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 2.298443\n",
            "Train Epoch: 0 [45120/50000 (90%)]\tLoss: 2.299006\n",
            "Train Epoch: 0 [45440/50000 (91%)]\tLoss: 2.302169\n",
            "Train Epoch: 0 [45760/50000 (91%)]\tLoss: 2.301176\n",
            "Train Epoch: 0 [46080/50000 (92%)]\tLoss: 2.304559\n",
            "Train Epoch: 0 [46400/50000 (93%)]\tLoss: 2.300999\n",
            "Train Epoch: 0 [46720/50000 (93%)]\tLoss: 2.302513\n",
            "Train Epoch: 0 [47040/50000 (94%)]\tLoss: 2.306230\n",
            "Train Epoch: 0 [47360/50000 (95%)]\tLoss: 2.300537\n",
            "Train Epoch: 0 [47680/50000 (95%)]\tLoss: 2.303182\n",
            "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 2.304463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DRkiDnbVvXVY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}